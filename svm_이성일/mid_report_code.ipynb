{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = pd.read_csv(\"./fashion-mnist_train.csv\")\n",
    "# load train data and copy them\n",
    "# df_train = trainSet.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3    pixel4    pixel5  pixel6  pixel7    pixel8   \n",
       "0     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000  \\\n",
       "1     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "2     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.019608   \n",
       "3     0.0     0.0     0.0  0.003922  0.007843     0.0     0.0  0.000000   \n",
       "4     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "\n",
       "   pixel9  pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779   \n",
       "0     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000  \\\n",
       "1     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "2     0.0      0.0  ...  0.000000       0.0       0.0  0.117647  0.168627   \n",
       "3     0.0      0.0  ...  0.011765       0.0       0.0  0.000000  0.000000   \n",
       "4     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0  0.000000       0.0       0.0       0.0       0.0  \n",
       "1  0.000000       0.0       0.0       0.0       0.0  \n",
       "2  0.000000       0.0       0.0       0.0       0.0  \n",
       "3  0.003922       0.0       0.0       0.0       0.0  \n",
       "4  0.000000       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating data and label\n",
    "X_train = trainSet.drop(['label'],axis = 1)\n",
    "X_label = trainSet['label']\n",
    "\n",
    "\n",
    "# do nomalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255.0\n",
    "\n",
    "#X_label\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set divide -> train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#split train&test\n",
    "seed = 99\n",
    "np.random.seed(seed)\n",
    "X_train, X_val,label_train,label_val = train_test_split(X_train,X_label,test_size =0.1, random_state= seed)\n",
    "# do standard scaling\n",
    "print(type(X_train))\n",
    "X_train=StandardScaler().fit_transform(X_train)\n",
    "X_val=StandardScaler().fit_transform(X_val)\n",
    "print(type(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 187)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA -> dimenstion Reducing\n",
    "pca = PCA(n_components=187, random_state=42)\n",
    "# n_components = 100 ~ 200\n",
    "# n_components = 187 --> by siyun.ipynb\n",
    "X_train_pca =pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_train_PCA1 = pd.DataFrame(X_train_pca)\n",
    "X_val_PCA1 = pd.DataFrame(X_val_pca)\n",
    "X_train_pca.shape\n",
    "\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Time: 7.87 minute\n"
     ]
    }
   ],
   "source": [
    "# svm model\n",
    "start = time.time()\n",
    "\n",
    "# Cost -->  13 / kernel --> gaussian /  gamma --> 1/# features\n",
    "\n",
    "# svc = SVC(C=1,kernel='rbf',gamma=\"auto\",probability = True) , n_component = 100\n",
    "# Train Accuracy score: 0.9651296296296297\n",
    "# Test Accuracy score: 0.874\n",
    "# time = 22m\n",
    "\n",
    "\n",
    "# svc = SVC(C=1,kernel='rbf',gamma=\"scale\",probability = True)\n",
    "# Train Accuracy score: 0.9010185185185186\n",
    "# Test Accuracy score: 0.8891666666666667\n",
    "# time = 5m\n",
    "\n",
    "# svc = SVC(C=0.9,kernel='rbf',gamma=\"auto\",probability = True)\n",
    "# Train Accuracy score: 0.9613518518518519\n",
    "# Test Accuracy score: 0.8723333333333333\n",
    "# time = 17m\n",
    "\n",
    "svc = SVC(C=1,kernel='rbf',gamma=\"scale\",probability = True) # n_ component = 200\n",
    "# Train Accuracy score: 0.9113888888888889\n",
    "# Test Accuracy score: 0.8945\n",
    "# time = 8m\n",
    "#svc = SVC(C=1,kernel='rbf',gamma=\"auto\",probability = True)\n",
    "svc.fit(X_train_PCA1,label_train)\n",
    "\n",
    "end = time.time()\n",
    "svm_time = end-start\n",
    "print(\"SVM Time: {:0.2f} minute\".format(svm_time/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 혼성모델\n",
    "# start1 = time.time()\n",
    "\n",
    "# random_forest = RandomForestClassifier(criterion='entropy', max_depth=70, n_estimators=100)\n",
    "# random_forest.fit(X_train_PCA1, Y_train)\n",
    "\n",
    "# end1 = time.time()\n",
    "# forest_time = end1-start1\n",
    "# print(\"Random Forest Time: {:0.2f} minute\".format(forest_time/60.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy score: 0.9105740740740741\n",
      "Validation Accuracy score: 0.895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       574\n",
      "           1       0.99      0.97      0.98       596\n",
      "           2       0.82      0.83      0.82       573\n",
      "           3       0.90      0.92      0.91       624\n",
      "           4       0.85      0.85      0.85       635\n",
      "           5       0.97      0.94      0.96       632\n",
      "           6       0.76      0.68      0.71       600\n",
      "           7       0.94      0.96      0.95       604\n",
      "           8       0.94      0.98      0.96       598\n",
      "           9       0.96      0.96      0.96       564\n",
      "\n",
      "    accuracy                           0.90      6000\n",
      "   macro avg       0.89      0.89      0.89      6000\n",
      "weighted avg       0.89      0.90      0.89      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "train_pred = svc.predict(X_train_PCA1)\n",
    "val_pred = svc.predict(X_val_PCA1)\n",
    "# X_test_pca\n",
    "svc_train = metrics.accuracy_score(label_train,train_pred)\n",
    "svc_accuracy = metrics.accuracy_score(label_val, val_pred)\n",
    "\n",
    "print(\"Train Accuracy score: {}\".format(svc_train))\n",
    "print(\"Validation Accuracy score: {}\".format(svc_accuracy))\n",
    "print(metrics.classification_report(label_val, val_pred))\n",
    "\n",
    "# y_train_forest = random_forest.predict(X_train_PCA1)\n",
    "# y_pred_forest = random_forest.predict(X_test_pca)\n",
    "# random_forest_train = metrics.accuracy_score(Y_train,y_train_forest)\n",
    "# random_forest_accuracy = metrics.accuracy_score(Y_val, y_pred_forest)\n",
    "\n",
    "# print(\"Train Accuracy score: {}\".format(random_forest_train))\n",
    "# print(\"Test Accuracy score: {}\".format(random_forest_accuracy))\n",
    "# print(metrics.classification_report(Y_val, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set load\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = \"./data/data\"\n",
    "file_names = [f for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
    "Test_set = []\n",
    "for file in file_names:\n",
    "    if file.endswith('png'):\n",
    "        file_path = os.path.join(data_dir,file)\n",
    "        img = Image.open(file_path)\n",
    "        if img.mode == 'RGB':\n",
    "            img = img.convert('L')\n",
    "        img_arr = list(img.getdata())\n",
    "        Test_set.append(img_arr)\n",
    "\n",
    "\n",
    "columns = [f'pixel_{i}' for i in range(28*28)]\n",
    "\n",
    "test_X = pd.DataFrame(Test_set, columns=columns)\n",
    "test_X = test_X.astype('float32')\n",
    "test_X /= 255.0\n",
    "\n",
    "test_df = StandardScaler().fit_transform(test_X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pca =pca.transform(test_df)\n",
    "test_PCA = pd.DataFrame(test_pca)\n",
    "test_pred = svc.predict(test_PCA)\n",
    "\n",
    "clip = test_pred[:10000]\n",
    "with open(\"./mAP/testResult.txt\", \"w\") as f:\n",
    "    for f_name, prediction in zip(file_names,clip):\n",
    "        f_name = f_name.replace(\".png\",\"\")\n",
    "        f.write(f\"{f_name} {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
